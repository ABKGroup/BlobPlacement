# This takes the the follwoing as input and generates the LEF and DEF files
#   1. hypergraph: Input is a file. The file format is as follows:
#       1. <net_name> <source node> <sink node> ...
#   2. cluster_file: Input is a dataframe file. The file format is as follows:
#       1. <Node Name>, <Type>, <Master>, <Height>, <Width>, <Cluster ID>
#          We may have two <Cluster ID 1..2..3> when we will go for 2-level
#          clustering
#       2. Type: inst, terminal
#   3. Input DEF file: From the input DEF file, the script extracts pin
#      locations, row information, dbu unit etc.
#   4. Output LEF file: The output LEF file is generated by the script contains
#      the following information:
#       1. MACRO definition for each cluster
#   5. Output DEF file: The output DEF file is generated by the script contains
#      the following information:
#       1. All the clusters are placed at center of the DEF file
#       2. The net connections of the clusters pin
#   6. Also, we write out a file for net weights.

# TODO
# Run the following test to ensure the code is working as expected
# 1. Generating the cluster hgr multiple times does not affect the output
# 2. Generating the cluster def file does not get impacted by the cluster hgr


from __future__ import annotations
from typing import List, Dict, Tuple, Optional, Union, Set, TextIO
import pandas as pd
import networkx as nx
import igraph as ig
import zlib
from gen_cluster import *
import os
import math
import time
from concurrent.futures import ProcessPoolExecutor
from functools import partial
from tqdm import tqdm
import concurrent.futures
import itertools
from multiprocessing import Pool

PORT_NET_WEIGHT = 10
INTRA_CLUSTER_NET_WEIGHT = 4
ITER = 10

class Cluster:
    '''
    Cluster of instances.
    '''
    def __init__(self, id:int, ar:float = 1.0,
                 util:float = 1.0) -> None:
        self.id:int = id
        self.name:Optional[str] = None
        self.insts: List[Inst] = []
        self.ports: List[Port] = []
        # Nets that are driven by the cluster
        self.dnets: List[Net] = []
        # This cluster is a sink for these nets
        # If a net is already in dnets then it will not be in snets
        self.snets: List[Net] = []
        # Nets that are inside the cluster
        self.nets: Optional[List[Net]] = None
        # Pointers to the parent cluster
        self.pCluster: Optional[Cluster] = None
        # Pointers to the child clusters
        self.cClusters: Optional[List[Cluster]] = None
        self.area:float = 0.0
        self.height:float = 0.0
        self.width:float = 0.0
        self.llx:Optional[int] = None
        self.lly:Optional[int] = None
        self.ar:float = ar
        self.util:float = util
        self.net2pin: Dict[Net, str] = {}

    def add_child_cluster(self, cluster:Cluster) -> None:
        if self.cClusters == None:
            self.cClusters = []
        self.cClusters.append(cluster)
        cluster.add_parent_cluster(self)

    def add_inst(self, inst:Inst) -> None:
        self.insts.append(inst)
        self.area += inst.width * inst.height

    def remove_inst(self, inst:Inst) -> None:
        self.insts.remove(inst)
        self.area -= inst.width * inst.height

    def add_port(self, port:Port) -> None:
        self.ports.append(port)

    def add_parent_cluster(self, cluster:Cluster) -> None:
        self.pCluster = cluster

    def get_name(self) -> str:
        if self.name == None:
            self.update_name()
        return self.name

    def update_name(self) -> None:
        if self.pCluster == None:
            self.name = f"cluster_{self.id}"
        else:
            self.name = f"{self.pCluster.get_name()}_{self.id}"
        return

    def add_driver_net(self, net:Net) -> None:
        """
        Add nets driven by the cluster
        """
        if net not in self.dnets:
            # self.dnets.add(net)
            self.dnets.append(net)

    def add_sink_net(self, net:Net) -> None:
        """
        Add nets that are sink for the cluster
        """
        if net not in self.dnets:
            # self.snets.add(net)
            if net not in self.snets:
                self.snets.append(net)

    def remove_driver_net(self, net:Net) -> None:
        self.dnets.remove(net)

    def remove_sink_net(self, net:Net) -> None:
        self.snets.remove(net)

    def update_util(self, util:float) -> None:
        self.util = util

    def write_pins(self, fp:TextIO, pin_name:str, x:float, y:float,
                   is_input:bool, pin_layer:str = 'M1') -> None:
        x = round(x, 3) # Round to 3 decimal places
        y = round(y, 3) # Round to 3 decimal places
        # print(f"Pin layer:{pin_layer}")
        fp.write(f"\tPIN {pin_name}\n")
        fp.write(f"\t\tDIRECTION {'INPUT' if is_input else 'OUTPUT'} ;\n")
        fp.write("\t\tUSE SIGNAL ;\n")
        fp.write("\t\tPORT\n")
        fp.write(f"\t\t\tLAYER {pin_layer} ;\n")
        fp.write(f"\t\t\tRECT {x} {y} {x} {y} ;\n")
        fp.write("\t\t\tEND\n")
        fp.write(f"\t\tEND {pin_name}\n")

    def write_lef(self, fp:TextIO, pin_layer:str = 'M1',
                  util:Optional[float] = None, ar:float = 1.0) -> None:
        
        if util is None:
            util = self.util

        fp.write(f"MACRO {self.get_name()}\n")
        fp.write(f"\tCLASS BLOCK ;\n")
        fp.write(f"\tORIGIN 0 0 ;\n")
        fp.write(f"\tFOREIGN {self.get_name()} 0 0 ;\n")
        
        if self.height == 0 and self.width == 0:
            self.width = round(math.sqrt(self.area * ar / util), 3)
            self.height = round(self.area / (util * self.width), 3)
            
        fp.write(f"\tSIZE {self.width} BY {self.height} ;\n")
        fp.write(f"\tSYMMETRY X Y ;\n")
        # fp.write(f"\tSITE CORE12T ;\n")
        ## Print Output Pins (Sinks)
        single_pin = False
        if not single_pin:
            i = 0
            for net in self.snets:
                if net.weight == 0:
                    continue
                pin_name = f"OP{i}"
                self.net2pin[net] = pin_name
                self.write_pins(fp, pin_name, self.width/2, self.height/2,
                                False, pin_layer)
                i += 1

            ## Print Input Pins (Drivers)
            i = 0
            for net in self.dnets:
                if net.weight == 0:
                    continue
                pin_name = f"IP{i}"
                self.net2pin[net] = pin_name
                self.write_pins(fp, pin_name, self.width/2,
                                self.height/2, True, pin_layer)
                i += 1
        else:
            pin_name = "P"
            for net in self.dnets:
                if net.weight == 0:
                    continue
                self.net2pin[net] = pin_name

            for net in self.snets:
                if net.weight == 0:
                    continue
                self.net2pin[net] = pin_name

            self.write_pins(fp, pin_name, self.width/2, self.height/2, True,
                            pin_layer)

        fp.write(f"END {self.get_name()}\n")

    def write_def_component(self, fp:TextIO, x, y,
                            is_fixed:bool = False) -> None:
        inst_name = re.sub('cluster_', 'inst_', self.get_name())
        if not is_fixed and self.llx is None and self.lly is None:
            fp.write(f"- {inst_name} {self.get_name()} +"
                f" PLACED ( {x} {y} ) N ;\n")
        elif self.llx is not None and self.lly is not None:
            fp.write(f"- {inst_name} {self.get_name()} +"
                f" FIXED ( {self.llx} {self.lly} ) N ;\n")
        else:
            fp.write(f"- {inst_name} {self.get_name()} +"
                f" FIXED ( {x} {y} ) N ;\n")
        return

class Inst:
    '''
    Class of instances.
    '''
    def __init__(self, id:int, name:str, width:float,
                 height:float, master_id:int) -> None:
        self.id:int = id
        self.name:str = name
        self.width:float = width
        self.height:float = height
        self.ll_x:Optional[float] = None
        self.ll_y:Optional[float] = None
        self.master_id:int = master_id
        self.driver:Set[Net] = set()    # Input nets
        self.sink:Set[Net] = set()      # Output nets
        ## Pointer to the cluster used during hypergraph generation
        ## Last element of the cluster list is the bottom level cluster
        self.cluster:Optional[List[Cluster]] = None
        self.isMacro:bool = False
        self.net2pin:Dict[Net, str] = {}

    ## Sink nets are driven by the instance (output nets)
    def add_sink(self, net:Net) -> None:
        self.sink.add(net)

    ## Drive nets drive the instance (input nets)
    def add_driver(self, net:Net) -> None:
        self.driver.add(net)

    def add_cluster(self, cluster:Cluster) -> None:
        if self.cluster == None:
            self.cluster = []
        self.cluster.append(cluster)

    def get_name(self) -> str:
        return self.name

    def update_location(self, x:float, y:float) -> None:
        self.ll_x = x
        self.ll_y = y

class Port:
    def __init__(self, id:int, name:str) -> None:
        self.id:int = id
        self.name:str = name
        self.net:Optional[Net] = None
        self.isInput:Optional[bool] = None
        self.cluster:Optional[List[Cluster]] = None

    def add_net(self, net:Net) -> None:
        self.net = net

    def set_input(self) -> None:
        self.isInput = True

    def set_output(self) -> None:
        self.isInput = False

    ## When the port is input it will have only sinks as it is a driver
    def add_sink(self, net:Net) -> None:
        self.add_net(net)
        self.set_input()

    ## When the port is output it will have only drivers as it is a sink
    def add_driver(self, net:Net) -> None:
        self.add_net(net)
        self.set_output()

    def add_cluster(self, cluster:Cluster) -> None:
        if self.cluster == None:
            self.cluster = []
        self.cluster.append(cluster)

    def get_name(self) -> str:
        return self.name

class Net:
    def __init__(self, id:int, name:str) -> None:
        self.id:int = id
        self.name:str = name
        self.sink:List[Union[Inst, Port]] = []
        self.driver:Optional[Union[Inst, Port]] = None
        self.weight:int = 1
        self.sinkCluster:Optional[List[Union[Cluster, Inst, Port]]] = None
        self.driverCluster:Optional[Union[Cluster, Inst, Port]] = None
        self.isPortNet:bool = False
        self.isMacroNet:bool = False

    def add_sink(self, inst:Union[Inst, Port]) -> None:
        self.sink.append(inst)
        inst.add_driver(self)

    def add_driver(self, inst:Union[Inst, Port]) -> None:
        self.driver = inst
        inst.add_sink(self)

    def set_port_net(self) -> None:
        self.isPortNet = True

    def set_macro_net(self) -> None:
        self.isMacroNet = True

    def update_weight(self, weight:int) -> None:
        self.weight = weight

    def add_sink_cluster(self, cluster:Union[Cluster, Inst, Port]) -> None:
        if self.sinkCluster == None:
            self.sinkCluster = []
        if self.driverCluster is not None and cluster != self.driverCluster:
            if cluster not in self.sinkCluster:
                self.sinkCluster.append(cluster)

    def add_driver_cluster(self, cluster:Union[Cluster, Inst, Port]) -> None:
        self.driverCluster = cluster
        if self.sinkCluster is not None and cluster in self.sinkCluster:
            self.sinkCluster.remove(cluster)

    def write_def_helper(self, fp:TextIO,
                       cluster:Union[Cluster, Port, Inst]) -> None:
        if isinstance(cluster, Cluster):
            driver_name = cluster.get_name().replace('cluster_', 'inst_')
            fp.write(f" ( {driver_name} "
                     f"{cluster.net2pin[self]} )\n")
        elif isinstance(cluster, Port):
            driver_name = cluster.get_name()
            fp.write(f" ( PIN {driver_name} )\n")
        else:
            print(f"Error:Net {self.name} has invalid driver cluster")
            exit()
        return

    def write_def_component(self, fp:TextIO) -> None:
        if self.driverCluster is None:
            print(f"Error:Net {self.name} has no driver cluster")
            exit()

        if self.sinkCluster is None:
            print(f"Error:Net {self.name} has no sink cluster")
            exit()

        fp.write(f"- {self.name}\n")
        self.write_def_helper(fp, self.driverCluster)

        for cluster in self.sinkCluster:
            self.write_def_helper(fp, cluster)

        fp.write(";\n")
        return

def generate_node_map_df(node_cluster_map_file:str) -> pd.DataFrame:
    ## Check if the file exists or not 
    if not os.path.exists(node_cluster_map_file):
        print(f"Error: node_cluster_map_file {node_cluster_map_file} does not exists")
        exit()
    
    fp = open(node_cluster_map_file, 'r')
    node_cluster_map = {}
    for line in fp.readlines():
        items = line.split(',')
        inst_name = re.sub(r'\\','', items[0])
        cluster_id = int(items[1].strip())
        node_cluster_map[inst_name] = cluster_id

    ## Convert node_cluster_map to pandas dataframe
    node_cluster_df = pd.DataFrame(node_cluster_map.items(), 
                                   columns=['Name', 'Cluster_id'])
    return node_cluster_df

class Design:
    def __init__(self, name:str, edge_file:str, node_file:str,
                 cluster_type:str = 'Louvain', cluster_map:Optional[str] = None,
                 dbu:int = 1000,
                 input_def:Optional[str] = None,
                 cluster_csv:Optional[str] = None,
                 hgr_file:Optional[str] = None,
                 input_lef:Optional[str] = None,
                 cluster_level:int = 1,
                 cluster_io:bool = False,
                 cluster_macro:bool = True,
                 macro_csv:Optional[str] = None,
                 output_dir:str = '.') -> None:
        # Current code does not support clustering IO
        self.name:str = name
        self.clusterLevel:int = cluster_level
        if os.path.exists(edge_file):
            self.edge_file:Optional[str] = edge_file
        else:
            print(f"Error: Edge file {edge_file} does not exists")
            exit(1)

        self.G:Optional[Union[nx.Graph, ig.Graph]] = None
        self.node_df:Optional[pd.DataFrame] = None
        if cluster_map is not None:
            cluster_node_df = generate_node_map_df(cluster_map)
        
        if cluster_type == 'Louvain':
            g_start_time = time.time()
            self.G, self.node_df = gen_nx_graph(node_file, self.edge_file)
            g_end_time = time.time()
            print(f"Time taken to generate graph: {g_end_time - g_start_time}")
            if cluster_map is not None:
                print(f"Cluster map file is present")
                self.node_df = self.node_df.merge(cluster_node_df,
                                                  on='Name', how='left')
        
            start_time = time.time()

            if 'Cluster_id' not in self.node_df.columns:
                self.node_df = gen_louvain_cluster(self.G, self.node_df)
            else:
                print('Utilizing the cluster map file')
                self.node_df = self.node_df[self.node_df['isNode'] == True]

        elif cluster_type == 'Leiden':
            print(f"Generating igraph")
            g_start_time = time.time()
            self.G, self.node_df = gen_ig_graph(node_file, self.edge_file)
            g_end_time = time.time()
            print(f"Time taken to generate graph: {g_end_time - g_start_time}")
            print(f"igraph generated")
            if cluster_map is not None:
                print(f"Cluster map file is present")
                self.node_df = self.node_df.merge(cluster_node_df,
                                                  on='Name', how='left')
            
            start_time = time.time()

            #Remove 'Cluster_id' column if it exists
            # if 'Cluster_id' in self.node_df.columns:
            #     self.node_df = self.node_df.drop(columns=['Cluster_id'])

            if 'Cluster_id' not in self.node_df.columns:
                self.node_df = gen_leiden_cluster(self.G, self.node_df,
                                              n_iteration = ITER)
            else:
                self.node_df = self.node_df[self.node_df['isNode'] == True]

        else:
            print(f'Error: Invalid cluster type {cluster_type}')
            exit()

        end_time = time.time()
        print(f"Time taken for clustering: {end_time - start_time} seconds")

        self.dbu:int = dbu
        ## This is the component count; Updates during write_cluster_lef
        ## function
        self.cluster_count = 0
        self.cluster_net_count = 0
        self.macro_count = 0
        self.clusterIO:bool = cluster_io
        self.clusterMacro:bool = cluster_macro
        self.hgrFile:Optional[str] = hgr_file
        self.macro_csv:Optional[str] = macro_csv
        self.clusterCsv:Optional[str] = cluster_csv
        self.inputDef:Optional[str] = input_def
        self.inputLef:Optional[str] = input_lef

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        self.outputDef:str = f"{output_dir}/{self.name}_cluster.def"
        self.outputLef:str = f"{output_dir}/{self.name}_cluster.lef"
        self.netWeight:str = f"{output_dir}/{self.name}.netweight"

        ## Clusters list contains only top level clusters
        self.clusters:List[Cluster] = []
        self.insts:List[Inst] = []
        self.ports:List[Port] = []
        self.nets:List[Net] = []
        self.cellMaster:List[str] = []
        ## Maps to access the objects by name, to find the object location in
        ## the design list you can use the object id
        self.portMap:Dict[str, Port] = {}
        self.instMap:Dict[str, Inst] = {}
        self.netMap:Dict[str, Net] = {}

    def __call__(self, threshold:float = 0.015, util:float = 1.0,
                 pin_layer:str = 'M1', ar:float = 1.0,
                 net_fanout_threshold:float = 0.05, outlier_csv=None) -> None:
        self.read_node_df()
        if self.macro_csv is not None:
            self.update_macro_location()
        start_time = time.time()
        self.read_hgr_file()
        end_time = time.time()
        print(f"Time taken to read hgr: {end_time - start_time}")
        start_time = time.time()
        print(f"Starting hierarchy clustering")
        self.run_hierarchy_cluster(threshold)
        end_time = time.time()
        print(f"Time taken for hierarchy clustering: {end_time - start_time}")

        if outlier_csv is not None:
            for outlier_csv_ in outlier_csv:
                with open(outlier_csv_, 'r') as f:
                    lines = f.readlines()
                    for line in lines:
                        sp = line.strip().split()
                        outlier = sp[0]
                        original_cluster = sp[1]
                        moving_cluster = sp[2]

                        outlierInst = self.instMap[outlier]

                        for cluster in self.clusters:
                            if cluster.cClusters is not None:
                                for ccluster in cluster.cClusters:
                                    if ccluster.get_name() == original_cluster:
                                        ccluster.remove_inst(outlierInst)
                            else:
                                if cluster.get_name() == original_cluster:
                                    cluster.remove_inst(outlierInst)

                        for cluster in self.clusters:
                            if cluster.cClusters is not None:
                                for ccluster in cluster.cClusters:
                                    if ccluster.get_name() == moving_cluster:
                                        ccluster.add_inst(outlierInst)
                            else:
                                if cluster.get_name() == moving_cluster:
                                    cluster.add_inst(outlierInst)

        self.update_cluster_connections()
        start_time = time.time()
        self.remove_parallel_nets()
        end_time = time.time()
        print(f"Time taken for removing parallel nets: {end_time - start_time}")
        # print(f"Pin layer1: {pin_layer}")
        self.write_cluster_lef(util, pin_layer, ar)
        self.write_cluster_instances()
        if self.inputDef is not None:
            self.write_def_file(self.inputDef, pin_layer, net_fanout_threshold)
        else:
            print("Warning: Input DEF file is not provided")
            exit()

        self.write_netweight(net_fanout_threshold)
        return

    # define a hashmap to store the net source and sink
    def get_hash_value(self, net:Net) -> int:
        hash_value = 0
        for inst in net.sink:
            hash_value += inst.id**2
        if net.driver is not None:
            hash_value += net.driver.id**2
        return hash_value

    def compare_net(self, net1:Net, net2:Net) -> bool:
        if net1.driver != net2.driver:
            return False

        sink1 = set(net1.sink)
        sink2 = set(net2.sink)
        if sink1 != sink2:
            return False
        return True

    def remove_parallel_nets(self) -> None:
        '''
        Removes parallel nets
        '''
        net2hash:Dict[int, List[Net]] = {}
        for net in self.nets:
            hash_value = self.get_hash_value(net)
            if hash_value not in net2hash:
                net2hash[hash_value] = []
            else:
                ## Check if the net is already present
                flag = False
                for tmp_net in net2hash[hash_value]:
                    if self.compare_net(net, tmp_net):
                        tmp_net.weight += net.weight
                        net.weight = 0
                        flag = True
                        break
                if flag:
                    continue
            net2hash[hash_value].append(net)
        return

    def add_inst(self, inst:Inst) -> None:
        self.instMap[inst.name] = inst
        self.insts.append(inst)

    def add_port(self, port:Port) -> None:
        self.portMap[port.name] = port
        self.ports.append(port)

    def add_net(self, net:Net) -> None:
        self.netMap[net.name] = net
        if net.id != len(self.nets):
            print(f"Warning: Updating id of net:{net.name}")
            net.id = len(self.nets)
        self.nets.append(net)

    def add_cluster(self, cluster:Cluster) -> None:
        self.clusters.append(cluster)

    def read_node_df(self) -> None:
        """
        Read the node_df and create the insts, ports
        """
        # Read the Instances
        if self.node_df is None:
            print("Error: node_df is None")
            exit()

        inst_df = self.node_df[self.node_df['Type'] == 'inst']\
                .reset_index(drop=True)
        inst_df = inst_df.drop_duplicates(subset='Name')
        inst_df = inst_df.reset_index(drop=True)

        self.cellMaster = inst_df['Master'].unique().tolist()
        std_cell_height = inst_df['Height'].min()
        print(f"Std cell height:{std_cell_height}")

        # Sort inst_df items based on cluster index
        inst_df = inst_df.sort_values(by=['Cluster_id'])
        macro_inst_list:List[Inst] = []
        for id, row in inst_df.iterrows():
            master_id = self.cellMaster.index(row['Master'])
            new_inst = Inst(id, row['Name'], float(row['Width']),
                            float(row['Height']), master_id)

            if row['Height'] > std_cell_height:
                new_inst.isMacro = True

            self.add_inst(new_inst)
            self.instMap[row['Name']] = new_inst

            if math.isnan(row['Cluster_id']):
                continue

            cluster_id = int(row['Cluster_id'])

            while len(self.clusters) <= cluster_id:
                new_cluster = Cluster(len(self.clusters))
                self.add_cluster(new_cluster)

            new_cluster = self.clusters[cluster_id]
            if not self.clusterMacro and new_inst.isMacro:
                macro_inst_list.append(new_inst)
                continue

            new_inst.add_cluster(new_cluster)
            new_cluster.add_inst(new_inst)

        # Read the ports
        port_df = self.node_df[self.node_df['Type'] == 'term']\
                    .reset_index(drop=True)
        port_df = port_df.drop_duplicates(subset='Name')
        port_df = port_df.reset_index(drop=True)

        for id, row in port_df.iterrows():
            new_port = Port(id, row['Name'])
            self.add_port(new_port)
            if self.clusterIO:
                cluster_id = int(row['Cluster_id'])

                if math.isnan(cluster_id):
                    continue

                while len(self.clusters) <= cluster_id:
                    new_cluster = Cluster(len(self.clusters))
                    self.add_cluster(new_cluster)
                new_cluster = self.clusters[cluster_id]
                new_port.add_cluster(new_cluster)
                new_cluster.add_port(new_port)

        # Create cluster for each macro and ensure the cluster size is
        # same as macro size
        for inst in macro_inst_list:
            macro_name = inst.name
            new_cluster = Cluster(len(self.clusters))
            # Update clsuter id of macro in node_df
            self.node_df.loc[self.node_df['Name'] == macro_name,
                             'Cluster_id'] = len(self.clusters)
            self.add_cluster(new_cluster)
            inst.add_cluster(new_cluster)
            new_cluster.add_inst(inst)
            new_cluster.height = inst.height
            new_cluster.width = inst.width
            new_cluster.area = inst.height * inst.width
            new_cluster.update_util(1.0)

    def update_macro_location(self) -> None:
        if self.macro_csv is None:
            print("Error: macro_csv is None")
            exit()

        macro_df = pd.read_csv(self.macro_csv)
        macro_df['Name'] = macro_df['Name'].replace(to_replace=r'[{}\\]',
                                                    value='', regex=True)
        for _, row in macro_df.iterrows():
            inst_name = row['Name']
            inst = self.instMap[inst_name]
            inst.update_location(int(row['llx']), int(row['lly']))
            inst.cluster[-1].llx = int(row['llx'])
            inst.cluster[-1].lly = int(row['lly'])


    def get_sub_graph(self, inst_list) -> Union[nx.Graph, ig.Graph]:
        if self.G is None:
            print("Error: Graph is not initialized")
            exit()

        if isinstance(self.G, nx.Graph):
            return self.G.subgraph(inst_list)
        elif isinstance(self.G, ig.Graph):
            index_list = [self.G.vs.find(name=inst).index for inst in inst_list]
            return self.G.subgraph(index_list)
        else:
            print("Error: Invalid graph type")
            exit()

    def gen_sub_cluster(self, id:int) -> pd.DataFrame:
        if self.node_df is None:
            print("Error: node_df is not initialized")
            exit()
        sub_cluster_df = self.node_df[self.node_df['Cluster_id'] == id]
        nodes = sub_cluster_df['Name'].values.tolist()
        H = self.get_sub_graph(nodes)
        tmp_df = pd.DataFrame({'Name': nodes})
        if isinstance(self.G, nx.Graph):
            tmp_df = gen_louvain_cluster(H, tmp_df)
        else:
            tmp_df = gen_leiden_cluster(H, tmp_df, n_iteration = ITER)
        return tmp_df

    def update_sub_cluster(self, id, cluster_df) -> None:
        tmp_cluster_df = cluster_df.sort_values(by=['Cluster_id'])
        cluster = self.clusters[id]
        cluster.cClusters = []

        for _, row in tmp_cluster_df.iterrows():
            node_name = row['Name']
            node_type = row['Type']
            cluster_id = int(row['Cluster_id'])
            while len(cluster.cClusters) <= cluster_id:
                new_cluster = Cluster(len(cluster.cClusters))
                cluster.add_child_cluster(new_cluster)
            new_cluster = cluster.cClusters[cluster_id]
            if node_type == 'inst':
                inst = self.instMap[node_name]
                inst.add_cluster(new_cluster)
                new_cluster.add_inst(inst)
            elif node_type == 'term':
                if self.clusterIO == False:
                    continue
                port = self.portMap[node_name]
                port.add_cluster(new_cluster)
                new_cluster.add_port(port)
            else:
                print(f"Error: Invalid node type {node_type}")
                exit()

    def process_cluster(self, cluster:Cluster, inst_threshold:float) -> None:
        if len(cluster.insts) >= inst_threshold:
            cluster_id = cluster.id
            tmp_cluster_df = self.gen_sub_cluster(cluster_id)
            tmp_cluster_df = self.node_df[['Name', 'Type']].\
                            merge(tmp_cluster_df, on='Name')
            self.update_sub_cluster(cluster_id, tmp_cluster_df)

    def run_hierarchy_cluster(self, threshold:float = 0.03,
                              n_cpu:int = 8) -> None:
        inst_threshold = threshold * len(self.insts)
        count = 0
        for cluster in tqdm(self.clusters):
            if len(cluster.insts) >= inst_threshold:
                cluster_id = cluster.id
                tmp_cluster_df = self.gen_sub_cluster(cluster_id)
                tmp_cluster_df = self.node_df[['Name', 'Type']].\
                                merge(tmp_cluster_df, on='Name')
                self.update_sub_cluster(cluster_id, tmp_cluster_df)
                count += 1

        # # Create a partial function with inst_threshold filled in
        # process_cluster_with_threshold = partial(self.process_cluster,
        #                                      inst_threshold=inst_threshold)

        # with ProcessPoolExecutor(max_workers = n_cpu) as executor:
        #     # Use map to parallelize
        #     # executor.map(process_cluster_with_threshold, self.clusters)
        #     list(tqdm(executor.map(process_cluster_with_threshold,
        #                            self.clusters),
        #               total=len(self.clusters)))

        # process_cluster_with_threshold = partial(self.process_cluster,
        #                                      inst_threshold=inst_threshold)
        # with concurrent.futures.ThreadPoolExecutor(max_workers=n_cpu) as executor:
        #     executor.map(process_cluster_with_threshold,
        #                  zip(itertools.repeat(self), self.clusters))

    def update_net_weight_if_inside_top_clusters(self, net:Net) -> None:
        cluster = set()

        ## Handle driver parent cluster
        if isinstance(net.driverCluster, Cluster):
            # if this has a parent cluster then check further
            if net.driverCluster.pCluster is None:
                return
            else:
                cluster.add(net.driverCluster.pCluster)
        else:
            ## Net driver is not part of cluster is it can not be inside
            ## a cluster
            return

        for sink_cluster in net.sinkCluster:
            if isinstance(sink_cluster, Cluster):
                if sink_cluster.pCluster is None:
                    return
                else:
                    cluster.add(sink_cluster.pCluster)
            else:
                return

            if len(cluster) > 1:
                return

        net.weight = INTRA_CLUSTER_NET_WEIGHT

        return

    ## TODO: Add option to ignore highfanout nets. If fanout threshold is 0
    ## TODO: then ignore fanout option, otherwise consider it.
    def update_cluster_connections(self) -> None:
        """
        Updates nets leaf cluster connections
        """
        self.cluster_net_count = 0
        for net in self.nets:
            cluster = None
            if net.driver is None:
                print(f"Warning: Net {net.name} does not have a driver")
                continue

            ## Update driving cluster or Port of the net
            if isinstance(net.driver, Port):
                if self.clusterIO:
                    if net.driver.cluster is not None:
                        cluster = net.driver.cluster[-1]
                    else:
                        print(f"Error: Cluster is not set for port: "
                              f"{net.driver.name}")
                        exit()
                else:
                    cluster = net.driver
            elif isinstance(net.driver, Inst):
                if net.driver.cluster is not None:
                    cluster = net.driver.cluster[-1]
                else:
                    print(f"Error: Cluster is not set for driver instance: "
                          f"{net.driver.name} of net {net.name}")
                    exit()
            else:
                print(f"Error: Invalid driver type for net {net.name}")
                exit()

            if cluster is not None:
                if isinstance(cluster, Cluster):
                    cluster.add_driver_net(net)
                net.add_driver_cluster(cluster)
            else:
                print(f"Warning: Cluster driver is not set for {net.name}")

            ## Update sink clusters of Port of the net
            for sink in net.sink:
                if isinstance(sink, Port):
                    if self.clusterIO:
                        if sink.cluster is not None:
                            cluster = sink.cluster[-1]
                        else:
                            print(f"Error: Cluster is not set for port: "
                                f"{sink.name}")
                            exit()
                    else:
                        cluster = sink
                elif isinstance(sink, Inst):
                    if sink.cluster is not None:
                        cluster = sink.cluster[-1]
                    else:
                        print(f"Error: Cluster is not set for sink instance: "
                              f"{sink.name} of net {net.name}")
                        exit()
                else:
                    print(f"Error: Invalid sink type for net {net.name}")
                    exit()

                if cluster is not None:
                    if isinstance(cluster, Cluster):
                        cluster.add_sink_net(net)
                    net.add_sink_cluster(cluster)

            ## Now check if the net is inside a leaf cluster
            if net.sinkCluster is None or len(net.sinkCluster) == 0:
                net.weight = 0
                continue

            # Check is this net is inside a top cluster
            self.update_net_weight_if_inside_top_clusters(net)
            # Check if this net is a port net
            if net.isPortNet:
                net.weight = PORT_NET_WEIGHT
            self.cluster_net_count += 1

    def write_netweight(self, net_fanout_threshold:float = 0.05) -> None:
        fp = open(self.netWeight, 'w')
        net_threshold = net_fanout_threshold * self.cluster_count
        for net in self.nets:
            if net.weight > 0:
                net_fanout = len(net.sinkCluster)
                if net_fanout < net_threshold or net_threshold == 0:
                    fp.write(f"{net.name} {net.weight}\n")
        fp.close()
        return

    def write_cluster_instances(self) -> None:
        cluster_details = re.sub(r'.lef', '.csv', self.outputLef)
        fp = open(cluster_details, 'w')
        for cluster in self.clusters:
            if cluster.cClusters is not None:
                for ccluster in cluster.cClusters:
                    for inst in ccluster.insts:
                        fp.write(f"{ccluster.get_name()},{inst.name},"
                                 f"{ccluster.width},{ccluster.height}\n")
            else:
                for inst in cluster.insts:
                    fp.write(f"{cluster.get_name()},{inst.name},"
                             f"{cluster.width},{cluster.height}\n")
        fp.close()
        return

    def write_cluster_lef(self, util:float = 1.0, pin_layer:str = 'M1',
                          ar:float = 1.0) -> None:
        if self.inputLef is None:
            print("Error: Input LEF file is not provided")
            exit()
        fp = open(self.inputLef, 'r')
        lines = fp.readlines()
        fp.close()

        fp = open(self.outputLef, 'w')

        for line in lines:
            if re.match(r'^\s*END LIBRARY', line):
                break
            fp.write(line)

        # print(f"Print layer2: {pin_layer}")

        ## Write the cluster lef
        self.cluster_count = 0
        for cluster in self.clusters:
            if cluster.cClusters is not None:
                for ccluster in cluster.cClusters:
                    if len(ccluster.insts) == 0:
                        continue
                    ccluster.write_lef(fp, pin_layer, util, ar)
                    self.cluster_count += 1
            else:
                if len(cluster.insts) > 0:
                    cluster.write_lef(fp, pin_layer, util, ar)
                    self.cluster_count += 1

        fp.write("END LIBRARY\n")
        fp.close()
        return

    def write_def_components(self, fp:TextIO, x:int, y:int) -> None:
        fp.write(f"COMPONENTS {self.cluster_count} ;\n")
        for cluster in self.clusters:
            if cluster.cClusters is not None:
                for ccluster in cluster.cClusters:
                    if len(ccluster.insts) == 0:
                        continue
                    ccluster.write_def_component(fp, x, y)
            else:
                if len(cluster.insts) > 0:
                    cluster.write_def_component(fp, x, y)

    def write_def_nets(self, fp:TextIO, threshold:float = 0) -> None:
        ## Find number of nets with fanout greater than threshold
        hfn = 0
        if threshold > 0:
            for net in self.nets:
                if net.weight == 0:
                    continue
                net_fanout = len(net.sinkCluster)
                if net_fanout >= threshold:
                    hfn += 1
        
        fp.write(f"NETS {self.cluster_net_count - hfn} ;\n")
        for net in self.nets:
            if net.weight == 0:
                continue

            net_fanout = len(net.sinkCluster)
            
            if threshold > 0 and net_fanout >= threshold:
                print(f"High fanout net name: {net.name} has fanout {net_fanout}")
                continue

            net.write_def_component(fp)

    def write_def_file(self, input_def:str, pin_layer="M1",
                       net_fanout_threshold:float = 0.05) -> None:
        fp = open(input_def, 'r')
        def_lines = fp.readlines()
        fp.close()

        fp = open(self.outputDef, 'w')

        die_width = 0.0
        die_height = 0.0

        i = 0
        while i < len(def_lines):
            line = def_lines[i]
            if line.startswith('DIEAREA'):
                items = line.split()
                die_height = int(items[7]) - int(items[3])
                die_width  = int(items[6]) - int(items[2])
            elif line.startswith('COMPONENTS'):
                while not line.startswith('END COMPONENTS'):
                    i += 1
                    line = def_lines[i]
                self.write_def_components(fp, int(die_width/2),
                                          int(die_height/2))
                # Write components
            elif line.startswith('NETS'):
                # Write nets
                print(f"Net fanout threshold: {net_fanout_threshold*self.cluster_count}")
                self.write_def_nets(fp, 
                                    self.cluster_count * net_fanout_threshold)
                while not line.startswith('END NETS'):
                    i += 1
                    line = def_lines[i]
            elif line.startswith('PINS'):
                # Write pins with updated pin layer to M1
                while not line.startswith('END PINS'):
                    tmp_line = re.sub(r'\s+LAYER\s+\S+', f' LAYER {pin_layer}',
                                      line)
                    fp.write(tmp_line)
                    i += 1
                    line = def_lines[i]
            elif line.startswith('SPECIALNETS'):
                while not line.startswith('END SPECIALNETS'):
                    line = def_lines[i]
                    i += 1
                line = def_lines[i]
            fp.write(line)
            i += 1
        fp.close()

    def add_new_net(self, net_name:str, source:Union[Inst, Port],
                    sinks:List[Union[Inst, Port]]):
        if net_name in self.netMap:
            print(f"Warning: Net {net_name} already exists")
            return
        new_net = Net(len(self.nets), net_name)
        self.add_net(new_net)

        if isinstance(source, Inst):
            new_net.add_driver(source)
            source.add_sink(new_net)
            if source.isMacro:
                new_net.set_macro_net()
        elif isinstance(source, Port):
            new_net.add_driver(source)
            source.add_sink(new_net)
            new_net.set_port_net()
        else:
            print(f"Error: For {net_name} Source {source} does not exists")
            exit(1)

        for sink in sinks:
            if isinstance(sink, Inst):
                new_net.add_sink(sink)
                sink.add_driver(new_net)
                if sink.isMacro:
                    new_net.set_macro_net()
            elif isinstance(sink, Port):
                new_net.add_sink(sink)
                sink.add_driver(new_net)
                new_net.set_port_net()
            else:
                print(f"Error: For {net_name} Sink {sink} does not exists")
                exit(1)

    def find_net_source_sink(self, items:List[str], isWdithPin:bool = False) \
            -> Tuple[Optional[Union[Inst, Port]], List[Union[Inst, Port]]]:
        # Find the first instance that belongs to a cluster
        source = None
        sinks = []
        i = -1
        for item in items:
            i += 1
            if item in self.instMap:
                inst = self.instMap[item]
                if inst.cluster is not None:
                    source = inst
                    break
            elif item in self.portMap:
                source = self.portMap[item]
                break
        i += 1
        while i < len(items):
            item = items[i]
            if item in self.instMap:
                inst = self.instMap[item]
                if inst.cluster is not None:
                    sinks.append(inst)
            elif item in self.portMap:
                sinks.append(self.portMap[item])
            i += 1

        # if source is None or len(sinks) == 0:
        #     print(f"Error: Net does not have a source or sink")

        return source, sinks

        # Find the sinks that belongs to some cluster

    def read_hgr_file(self, hgrFile:Optional[str] = None,
                      isWithPin:bool = False) -> None:
        if not self.hgrFile or os.path.exists(self.hgrFile) == False:
            if not hgrFile or os.path.exists(hgrFile) == False:
                print("Error: hgrFile is not provided")
                exit(1)
            self.hgrFile = hgrFile

        # fp = open(self.hgrFile, 'r')
        # lines = fp.readlines()
        # fp.close()
        with open(self.hgrFile, 'r') as fp:
            for line in fp:
                # Remove all {}\ from line
                line = re.sub(r'\{|\}|\\', '', line)
                items = line.split()
                if len(items) > 2:
                    net_name = items[0]
                    source, sinks = self.find_net_source_sink(items[1:], isWithPin)
                    if len(sinks) == 0 or source is None:
                        print(f"Warning: Check Net: {items} instaces are not in clusters")
                        continue
                    self.add_new_net(net_name, source, sinks)
                else:
                    print(f"Warning: Check Net: {items}")

